{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n#import tensorflow as tf\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom sklearn.metrics import f1_score, precision_score, recall_score, classification_report, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-17T11:57:46.309516Z","iopub.execute_input":"2021-09-17T11:57:46.310799Z","iopub.status.idle":"2021-09-17T11:57:46.322834Z","shell.execute_reply.started":"2021-09-17T11:57:46.310727Z","shell.execute_reply":"2021-09-17T11:57:46.321591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to evaluate: accuracy, precision, recall, f1-score\n\ndef calculate_results(y_true, y_pred):\n  \"\"\"\n  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n\n  Args:\n  -----\n  y_true = true labels in the form of a 1D array\n  y_pred = predicted labels in the form of a 1D array\n\n  Returns a dictionary of accuracy, precision, recall, f1-score.\n  \"\"\"\n  # Calculate model accuracy\n  model_accuracy = accuracy_score(y_true, y_pred) * 100\n  # Calculate model precision, recall and f1 score using \"weighted\" average\n  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n  model_results = {\"accuracy\": model_accuracy,\n                  \"precision\": model_precision,\n                  \"recall\": model_recall,\n                  \"f1\": model_f1}\n  return model_results\n\n\n# Create a helper function to compare our baseline results to new model results\ndef compare_baseline_to_new_results(baseline_results, new_model_results):\n  for key, value in baseline_results.items():\n    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-17T11:57:46.325782Z","iopub.execute_input":"2021-09-17T11:57:46.327028Z","iopub.status.idle":"2021-09-17T11:57:46.344876Z","shell.execute_reply.started":"2021-09-17T11:57:46.326951Z","shell.execute_reply":"2021-09-17T11:57:46.344134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_true = pd.read_csv(\"../input/banfakepreprocessed/LabeledAuthentic-7K.csv\")\ndf_fake = pd.read_csv(\"../input/banfakepreprocessed/Fake-1K.csv\")\n\ndataset = pd.concat([df_true, df_fake], axis = 0)\n\nX = dataset[\"content\"]\ny = dataset[\"label\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T11:57:46.346226Z","iopub.execute_input":"2021-09-17T11:57:46.346723Z","iopub.status.idle":"2021-09-17T11:57:47.346604Z","shell.execute_reply.started":"2021-09-17T11:57:46.346680Z","shell.execute_reply":"2021-09-17T11:57:47.345858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = feature_extraction.text.CountVectorizer()\ntrain_count = count.fit_transform(X_train)\ntest_count = count.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T11:57:47.348264Z","iopub.execute_input":"2021-09-17T11:57:47.349698Z","iopub.status.idle":"2021-09-17T11:57:49.634911Z","shell.execute_reply.started":"2021-09-17T11:57:47.349643Z","shell.execute_reply":"2021-09-17T11:57:49.634030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf = TfidfVectorizer(ngram_range = (1, 2), analyzer = 'word')\ntrain_tfidf = tfidf.fit_transform(X_train)\ntest_tfidf = tfidf.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T11:57:49.636231Z","iopub.execute_input":"2021-09-17T11:57:49.637602Z","iopub.status.idle":"2021-09-17T11:57:56.076700Z","shell.execute_reply.started":"2021-09-17T11:57:49.637555Z","shell.execute_reply":"2021-09-17T11:57:56.075935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_preds(y_true, y_preds):\n    \n    accuracy = accuracy_score(y_true, y_preds)\n    precision = precision_score(y_true, y_preds)\n    recall = recall_score(y_true, y_preds)\n    f1 = f1_score(y_true, y_preds)\n    \n    metric_dict = {\"accuracy\": round(accuracy, 2),\n                   \"precision\": round(precision, 2),\n                   \"recall\": round(recall, 2),\n                   \"f1\": round(f1, 2)}\n    \n    print(f\"Accucary: {accuracy * 100:.02f}%\")\n    print(f\"Precision: {precision * 100:.02f}%\")\n    print(f\"Recall: {recall * 100:.02f}%\")\n    print(f\"F1: {f1 * 100:.02f}%\")\n    \n    return metric_dict","metadata":{"execution":{"iopub.status.busy":"2021-09-17T11:57:56.078368Z","iopub.execute_input":"2021-09-17T11:57:56.079545Z","iopub.status.idle":"2021-09-17T11:57:56.088945Z","shell.execute_reply.started":"2021-09-17T11:57:56.079488Z","shell.execute_reply":"2021-09-17T11:57:56.087853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_grid = {'n_estimators': [int(x) for x in np.linspace(200, 2000, 200)],\n              'max_features': ['auto', 'sqrt','log2'],\n              'max_depth': [int(x) for x in np.linspace(10, 1000, 50)],\n              'min_samples_split': [2, 5, 10, 14],\n              'min_samples_leaf': [1, 2, 4, 6, 8]}\n\ngrid = GridSearchCV(RandomForestClassifier(), param_grid, cv = 5, verbose = 2)\ngrid.fit(train_tfidf, y_train)\n\nprint(\"Train Accuracy: %.3f\", grid.best_estimator_.score(train_tfidf, y_train))\nprint(\"Test Accuracy: %.3f\", grid.best_estimator_.score(test_tfidf, y_test))\nprint(\"Best Score: %.3f\", grid.best_score_)\nprint(\"Best Parameters: %.3f\", grid.best_params_)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T16:15:09.921137Z","iopub.execute_input":"2021-09-17T16:15:09.921496Z","iopub.status.idle":"2021-09-17T16:15:14.649204Z","shell.execute_reply.started":"2021-09-17T16:15:09.921461Z","shell.execute_reply":"2021-09-17T16:15:14.647599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}