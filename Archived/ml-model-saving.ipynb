{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Imports","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# Imports\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#import tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom imblearn.under_sampling import NearMiss, RandomUnderSampler\nfrom imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n\nfrom mlxtend.classifier import StackingCVClassifier\n\nfrom joblib import dump, load","metadata":{"execution":{"iopub.status.busy":"2021-09-23T03:17:43.566980Z","iopub.execute_input":"2021-09-23T03:17:43.567366Z","iopub.status.idle":"2021-09-23T03:17:44.961893Z","shell.execute_reply.started":"2021-09-23T03:17:43.567275Z","shell.execute_reply":"2021-09-23T03:17:44.961199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from warnings import simplefilter\nfrom sklearn.exceptions import ConvergenceWarning\nsimplefilter(\"ignore\", category=ConvergenceWarning)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T03:17:44.963764Z","iopub.execute_input":"2021-09-23T03:17:44.964591Z","iopub.status.idle":"2021-09-23T03:17:44.969146Z","shell.execute_reply.started":"2021-09-23T03:17:44.964546Z","shell.execute_reply":"2021-09-23T03:17:44.968201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to evaluate: accuracy, precision, recall, f1-score\n\ndef calculate_results(y_true, y_pred):\n  \"\"\"\n  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n\n  Args:\n  -----\n  y_true = true labels in the form of a 1D array\n  y_pred = predicted labels in the form of a 1D array\n\n  Returns a dictionary of accuracy, precision, recall, f1-score.\n  \"\"\"\n  # Calculate model accuracy\n  model_accuracy = accuracy_score(y_true, y_pred) * 100\n  # Calculate model precision, recall and f1 score using \"weighted\" average\n  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n  model_results = {\"accuracy\": model_accuracy,\n                  \"precision\": model_precision,\n                  \"recall\": model_recall,\n                  \"f1\": model_f1}\n  return model_results\n\n\n# Create a helper function to compare our baseline results to new model results\ndef compare_baseline_to_new_results(baseline_results, new_model_results):\n  for key, value in baseline_results.items():\n    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-23T03:17:44.971339Z","iopub.execute_input":"2021-09-23T03:17:44.971838Z","iopub.status.idle":"2021-09-23T03:17:44.984388Z","shell.execute_reply.started":"2021-09-23T03:17:44.971789Z","shell.execute_reply":"2021-09-23T03:17:44.983507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the font scale\nsns.set(font_scale = 1.5)\n\ndef plot_conf_mat(conf_mat):\n    \"\"\"\n    Plots a confusion matrix using Seaborn's heatmap().\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(4, 4))\n    ax = sns.heatmap(conf_mat,\n                     fmt=\"d\",\n                     annot=True, # Annotate the boxes \n                     cbar=False)\n    plt.xlabel('Predicted label')\n    plt.ylabel('True label');","metadata":{"execution":{"iopub.status.busy":"2021-09-23T03:17:44.987134Z","iopub.execute_input":"2021-09-23T03:17:44.987816Z","iopub.status.idle":"2021-09-23T03:17:45.002632Z","shell.execute_reply.started":"2021-09-23T03:17:44.987681Z","shell.execute_reply":"2021-09-23T03:17:45.001562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Data","metadata":{}},{"cell_type":"code","source":"df_true = pd.read_csv(\"../input/banfakepreprocessed/Authentic-48K.csv\")\ndf_fake = pd.read_csv(\"../input/banfakepreprocessed/Fake-1K.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-23T03:17:45.003854Z","iopub.execute_input":"2021-09-23T03:17:45.004248Z","iopub.status.idle":"2021-09-23T03:17:49.695996Z","shell.execute_reply.started":"2021-09-23T03:17:45.004219Z","shell.execute_reply":"2021-09-23T03:17:49.695061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = pd.concat([df_true, df_fake], axis = 0)\ndataset","metadata":{"execution":{"iopub.status.busy":"2021-09-23T03:17:49.697361Z","iopub.execute_input":"2021-09-23T03:17:49.697734Z","iopub.status.idle":"2021-09-23T03:17:49.725432Z","shell.execute_reply.started":"2021-09-23T03:17:49.697691Z","shell.execute_reply":"2021-09-23T03:17:49.724656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_true, count_fake = dataset[\"label\"].value_counts()\ncount_true, count_fake","metadata":{"execution":{"iopub.status.busy":"2021-09-23T03:17:49.726491Z","iopub.execute_input":"2021-09-23T03:17:49.726718Z","iopub.status.idle":"2021-09-23T03:17:49.738973Z","shell.execute_reply.started":"2021-09-23T03:17:49.726693Z","shell.execute_reply":"2021-09-23T03:17:49.738327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Numerical Representations\n### 3.1. Count Vectorizer","metadata":{}},{"cell_type":"code","source":"def count(data):\n    \n    df_temp = data.copy(deep = True)\n    df = dataset.copy(deep = True)\n    df_temp[\"content\"] = df_temp[\"content\"].fillna(' ')\n    df[\"content\"] = df[\"content\"].fillna(' ')\n\n    count_vectorizer = CountVectorizer()\n    count_vectorizer.fit(df[\"content\"])\n\n    list_corpus = df_temp[\"content\"].tolist()\n    list_labels = df_temp[\"label\"].tolist()\n    \n    X = count_vectorizer.transform(list_corpus)\n    \n    return X, list_labels","metadata":{"execution":{"iopub.status.busy":"2021-09-23T03:17:49.739934Z","iopub.execute_input":"2021-09-23T03:17:49.740877Z","iopub.status.idle":"2021-09-23T03:17:49.751417Z","shell.execute_reply.started":"2021-09-23T03:17:49.740840Z","shell.execute_reply":"2021-09-23T03:17:49.750343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2. Tfidf Vectorizer","metadata":{}},{"cell_type":"code","source":"def tfidf(data, ngrams = 1):\n\n    df_temp = data.copy(deep = True)\n    df = dataset.copy(deep = True)\n    df_temp[\"content\"] = df_temp[\"content\"].fillna(' ')\n    df[\"content\"] = df[\"content\"].fillna(' ')\n    \n    tfidf_vectorizer = TfidfVectorizer(ngram_range = (1, ngrams))\n    tfidf_vectorizer.fit(df['content'])\n\n    list_corpus = df_temp[\"content\"].tolist()\n    list_labels = df_temp[\"label\"].tolist()\n\n    X = tfidf_vectorizer.transform(list_corpus)\n    \n    return X, list_labels","metadata":{"execution":{"iopub.status.busy":"2021-09-23T03:17:49.752541Z","iopub.execute_input":"2021-09-23T03:17:49.752782Z","iopub.status.idle":"2021-09-23T03:17:49.768234Z","shell.execute_reply.started":"2021-09-23T03:17:49.752757Z","shell.execute_reply":"2021-09-23T03:17:49.767273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Defining models\n### 4.1. Logistic Regression","metadata":{}},{"cell_type":"code","source":"def logistic_regression(X_train, X_test, y_train, y_test, preprocessor):\n    \n    folds = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 40)\n    \n    clf = LogisticRegressionCV(cv = folds, solver = 'saga', multi_class = 'multinomial', n_jobs = -1)\n    clf.fit(X_train, y_train)\n\n    result = pd.DataFrame(columns = ['Preprocessing', 'Model', 'Accuracy','F1-score-0', 'F1-score-1'])\n    \n    y_pred = clf.predict(X_test)\n    \n    accuracy = accuracy_score(y_test, y_pred)\n    precision, recall, fscore, support = score(y_test, y_pred)\n    calc = f1_score(y_test, y_pred)\n    \n    result = result.append({'Preprocessing': preprocessor, \n                            'Model': f'Logistic Regression', 'Accuracy': accuracy,\n                            'F1-score-0': fscore[0], 'F1-score-1': fscore[1]}, ignore_index = True)\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-09-23T03:17:49.771944Z","iopub.execute_input":"2021-09-23T03:17:49.772267Z","iopub.status.idle":"2021-09-23T03:17:49.780939Z","shell.execute_reply.started":"2021-09-23T03:17:49.772215Z","shell.execute_reply":"2021-09-23T03:17:49.779953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2. Support Vector Machine","metadata":{}},{"cell_type":"code","source":"def support_vector_machine(X_train, X_test, y_train, y_test, preprocessor):\n    \n    clf = SVC(kernel = 'rbf', gamma = 1, C = 10)\n    clf.fit(X_train, y_train)\n\n    result = pd.DataFrame(columns = ['Preprocessing', 'Model', 'Accuracy', 'F1-score-0', 'F1-score-1'])\n    \n    y_pred = clf.predict(X_test)\n    \n    accuracy = accuracy_score(y_test, y_pred)\n    precision, recall, fscore, support = score(y_test, y_pred)\n    calc = f1_score(y_test, y_pred)\n    \n    result = result.append({'Preprocessing': preprocessor, \n                            'Model': f'Support Vector Machine', 'Accuracy': accuracy,\n                            'F1-score-0': fscore[0], 'F1-score-1': fscore[1]}, ignore_index = True)\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-09-23T03:17:49.782349Z","iopub.execute_input":"2021-09-23T03:17:49.782696Z","iopub.status.idle":"2021-09-23T03:17:49.793025Z","shell.execute_reply.started":"2021-09-23T03:17:49.782656Z","shell.execute_reply":"2021-09-23T03:17:49.792148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.3. Multinomial Naive Bayes","metadata":{}},{"cell_type":"code","source":"def multinomial_nb(X_train, X_test, y_train, y_test, preprocessor):\n    \n    clf = MultinomialNB(alpha = 0.01)\n    clf.fit(X_train, y_train)\n\n    result = pd.DataFrame(columns = ['Preprocessing', 'Model', 'Accuracy', 'F1-score-0', 'F1-score-1'])\n    \n    y_pred = clf.predict(X_test)\n    \n    accuracy = accuracy_score(y_test, y_pred)\n    precision, recall, fscore, support = score(y_test, y_pred)\n    calc = f1_score(y_test, y_pred)\n    \n    result = result.append({'Preprocessing': preprocessor, \n                            'Model': f'Multinomial Naive Bayes', 'Accuracy': accuracy,\n                            'F1-score-0': fscore[0], 'F1-score-1': fscore[1]}, ignore_index = True)\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-09-23T03:17:49.796098Z","iopub.execute_input":"2021-09-23T03:17:49.796326Z","iopub.status.idle":"2021-09-23T03:17:49.809318Z","shell.execute_reply.started":"2021-09-23T03:17:49.796302Z","shell.execute_reply":"2021-09-23T03:17:49.808573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.4. Bernoulli Naive Bayes","metadata":{}},{"cell_type":"code","source":"def bernoulli_nb(X_train, X_test, y_train, y_test, preprocessor):\n    \n    clf = BernoulliNB(alpha = 0.01)\n    clf.fit(X_train, y_train)\n\n    result = pd.DataFrame(columns = ['Preprocessing', 'Model', 'Accuracy', 'F1-score-0', 'F1-score-1'])\n    \n    y_pred = clf.predict(X_test)\n    \n    accuracy = accuracy_score(y_test, y_pred)\n    precision, recall, fscore, support = score(y_test, y_pred)\n    calc = f1_score(y_test, y_pred)\n    \n    result = result.append({'Preprocessing': preprocessor, \n                            'Model': f'Bernoulli Naive Bayes', 'Accuracy': accuracy,\n                            'F1-score-0': fscore[0], 'F1-score-1': fscore[1]}, ignore_index = True)\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-09-23T03:17:49.810197Z","iopub.execute_input":"2021-09-23T03:17:49.810419Z","iopub.status.idle":"2021-09-23T03:17:49.823295Z","shell.execute_reply.started":"2021-09-23T03:17:49.810393Z","shell.execute_reply":"2021-09-23T03:17:49.822229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.5. Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"def random_forest(X_train, X_test, y_train, y_test, preprocessor):\n    \n    clf = RandomForestClassifier(n_estimators= 400, max_features = 'sqrt')\n    clf.fit(X_train, y_train)\n\n    result = pd.DataFrame(columns = ['Preprocessing', 'Model', 'Accuracy', 'F1-score-0', 'F1-score-1'])\n    \n    y_pred = clf.predict(X_test)\n    \n    accuracy = accuracy_score(y_test, y_pred)\n    precision, recall, fscore, support = score(y_test, y_pred)\n    calc = f1_score(y_test, y_pred)\n    \n    result = result.append({'Preprocessing': preprocessor, \n                            'Model': f'Random Forest Classifier', 'Accuracy': accuracy,\n                            'F1-score-0': fscore[0], 'F1-score-1': fscore[1]}, ignore_index = True)\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-09-23T03:17:49.824470Z","iopub.execute_input":"2021-09-23T03:17:49.824735Z","iopub.status.idle":"2021-09-23T03:17:49.839750Z","shell.execute_reply.started":"2021-09-23T03:17:49.824697Z","shell.execute_reply":"2021-09-23T03:17:49.839105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.6. Decision Tree","metadata":{}},{"cell_type":"code","source":"def decision_tree(X_train, X_test, y_train, y_test, preprocessor):\n    \n    clf = DecisionTreeClassifier(criterion = 'gini', max_depth = 6)\n    clf.fit(X_train, y_train)\n\n    result = pd.DataFrame(columns = ['Preprocessing', 'Model', 'Accuracy', 'F1-score-0', 'F1-score-1'])\n    \n    y_pred = clf.predict(X_test)\n    \n    accuracy = accuracy_score(y_test, y_pred)\n    precision, recall, fscore, support = score(y_test, y_pred)\n    calc = f1_score(y_test, y_pred)\n    \n    result = result.append({'Preprocessing': preprocessor, \n                            'Model': f'Decision Tree Classifier', 'Accuracy': accuracy,\n                            'F1-score-0': fscore[0], 'F1-score-1': fscore[1]}, ignore_index = True)\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-09-23T03:17:49.840808Z","iopub.execute_input":"2021-09-23T03:17:49.841147Z","iopub.status.idle":"2021-09-23T03:17:49.852750Z","shell.execute_reply.started":"2021-09-23T03:17:49.841119Z","shell.execute_reply":"2021-09-23T03:17:49.851933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Modeling\n### 5.1. Baseline\n#### 5.1.1. Count","metadata":{}},{"cell_type":"code","source":"naive_over_sample = RandomOverSampler(sampling_strategy = 'minority')\n\n# Using Count\nX, y = count(dataset_train)\nX_test, y_test = count(dataset_test)\nX_train, y_train = naive_over_sample.fit_resample(X, y)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T03:19:00.562450Z","iopub.execute_input":"2021-09-23T03:19:00.562761Z","iopub.status.idle":"2021-09-23T03:19:00.683357Z","shell.execute_reply.started":"2021-09-23T03:19:00.562732Z","shell.execute_reply":"2021-09-23T03:19:00.682243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folds = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 40)\n    \nclf = LogisticRegressionCV(cv = folds, solver = 'saga', multi_class = 'multinomial', n_jobs = -1)\nclf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:37:03.917532Z","iopub.status.idle":"2021-09-21T12:37:03.917868Z","shell.execute_reply.started":"2021-09-21T12:37:03.917695Z","shell.execute_reply":"2021-09-21T12:37:03.917716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dump(clf, filename = \"baseline-count-LR.joblib\")","metadata":{"execution":{"iopub.status.busy":"2021-09-21T06:28:51.004832Z","iopub.execute_input":"2021-09-21T06:28:51.005243Z","iopub.status.idle":"2021-09-21T06:28:51.100519Z","shell.execute_reply.started":"2021-09-21T06:28:51.005166Z","shell.execute_reply":"2021-09-21T06:28:51.099726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.1.2. TFIDF-1","metadata":{}},{"cell_type":"code","source":"# result_baseline_tfidf1 = pd.DataFrame(columns = ['Preprocessing', 'Model', 'Accuracy', 'F1-score', 'F1-score-0', 'F1-score-1'])\n\n# # Using Tfidf 1-gram\n# X, y = tfidf(dataset)\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n# result_baseline_tfidf1 = result_baseline_tfidf1.append(logistic_regression(X_train, X_test, y_train, y_test, 'Tfidf 1-gram'), ignore_index = True)\n# result_baseline_tfidf1 = result_baseline_tfidf1.append(support_vector_machine(X_train, X_test, y_train, y_test, 'Tfidf 1-gram'), ignore_index = True)\n# result_baseline_tfidf1 = result_baseline_tfidf1.append(multinomial_nb(X_train, X_test, y_train, y_test, 'Tfidf 1-gram'), ignore_index = True)\n# result_baseline_tfidf1 = result_baseline_tfidf1.append(bernoulli_nb(X_train, X_test, y_train, y_test, 'Tfidf 1-gram'), ignore_index = True)\n\n# result_baseline_tfidf1","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:35:33.667293Z","iopub.execute_input":"2021-09-17T17:35:33.667616Z","iopub.status.idle":"2021-09-17T17:36:08.698117Z","shell.execute_reply.started":"2021-09-17T17:35:33.667578Z","shell.execute_reply":"2021-09-17T17:36:08.697216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.1.3. TFIDF-2","metadata":{}},{"cell_type":"code","source":"result_baseline_tfidf1 = pd.DataFrame(columns = ['Preprocessing', 'Model', 'Accuracy', 'F1-score-0', 'F1-score-1'])\n\n# Using Tfidf 2-gram\nX, y = tfidf(dataset)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:37:10.133786Z","iopub.execute_input":"2021-09-21T12:37:10.134337Z","iopub.status.idle":"2021-09-21T12:38:03.193844Z","shell.execute_reply.started":"2021-09-21T12:37:10.134287Z","shell.execute_reply":"2021-09-21T12:38:03.192724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folds = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 40)\n    \nclf = SVC(kernel = 'rbf', gamma = 1, C = 10)\nclf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T13:42:44.570995Z","iopub.execute_input":"2021-09-21T13:42:44.571415Z","iopub.status.idle":"2021-09-21T14:22:37.055404Z","shell.execute_reply.started":"2021-09-21T13:42:44.571371Z","shell.execute_reply":"2021-09-21T14:22:37.052922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dump(clf, filename = \"baseline-tfidf2-SVM.joblib\")","metadata":{"execution":{"iopub.status.busy":"2021-09-21T14:22:37.061203Z","iopub.execute_input":"2021-09-21T14:22:37.061618Z","iopub.status.idle":"2021-09-21T14:22:37.104395Z","shell.execute_reply.started":"2021-09-21T14:22:37.061508Z","shell.execute_reply":"2021-09-21T14:22:37.103579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}