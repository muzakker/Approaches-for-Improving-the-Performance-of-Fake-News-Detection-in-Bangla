{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Imports","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-16T05:16:09.956871Z","iopub.execute_input":"2021-09-16T05:16:09.957853Z","iopub.status.idle":"2021-09-16T05:16:11.20099Z","shell.execute_reply.started":"2021-09-16T05:16:09.957688Z","shell.execute_reply":"2021-09-16T05:16:11.2001Z"}}},{"cell_type":"code","source":"# Imports\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#import tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom imblearn.under_sampling import NearMiss, RandomUnderSampler\nfrom imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:53.054556Z","iopub.execute_input":"2021-09-17T17:36:53.054810Z","iopub.status.idle":"2021-09-17T17:36:53.061552Z","shell.execute_reply.started":"2021-09-17T17:36:53.054784Z","shell.execute_reply":"2021-09-17T17:36:53.060581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from warnings import simplefilter\nfrom sklearn.exceptions import ConvergenceWarning\nsimplefilter(\"ignore\", category=ConvergenceWarning)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:53.063622Z","iopub.execute_input":"2021-09-17T17:36:53.063947Z","iopub.status.idle":"2021-09-17T17:36:53.074175Z","shell.execute_reply.started":"2021-09-17T17:36:53.063907Z","shell.execute_reply":"2021-09-17T17:36:53.073239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Functions","metadata":{}},{"cell_type":"code","source":"# Function to evaluate: accuracy, precision, recall, f1-score\n\ndef calculate_results(y_true, y_pred):\n  \"\"\"\n  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n\n  Args:\n  -----\n  y_true = true labels in the form of a 1D array\n  y_pred = predicted labels in the form of a 1D array\n\n  Returns a dictionary of accuracy, precision, recall, f1-score.\n  \"\"\"\n  # Calculate model accuracy\n  model_accuracy = accuracy_score(y_true, y_pred) * 100\n  # Calculate model precision, recall and f1 score using \"weighted\" average\n  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n  model_results = {\"accuracy\": model_accuracy,\n                  \"precision\": model_precision,\n                  \"recall\": model_recall,\n                  \"f1\": model_f1}\n  return model_results\n\n\n# Create a helper function to compare our baseline results to new model results\ndef compare_baseline_to_new_results(baseline_results, new_model_results):\n  for key, value in baseline_results.items():\n    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:53.075582Z","iopub.execute_input":"2021-09-17T17:36:53.075829Z","iopub.status.idle":"2021-09-17T17:36:53.088303Z","shell.execute_reply.started":"2021-09-17T17:36:53.075804Z","shell.execute_reply":"2021-09-17T17:36:53.087172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the font scale\nsns.set(font_scale = 1.5)\n\ndef plot_conf_mat(conf_mat):\n    \"\"\"\n    Plots a confusion matrix using Seaborn's heatmap().\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(4, 4))\n    ax = sns.heatmap(conf_mat,\n                     fmt=\"d\",\n                     annot=True, # Annotate the boxes \n                     cbar=False)\n    plt.xlabel('Predicted label')\n    plt.ylabel('True label');","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:53.090451Z","iopub.execute_input":"2021-09-17T17:36:53.090663Z","iopub.status.idle":"2021-09-17T17:36:53.105935Z","shell.execute_reply.started":"2021-09-17T17:36:53.090639Z","shell.execute_reply":"2021-09-17T17:36:53.105264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Working with Data","metadata":{}},{"cell_type":"code","source":"df_true = pd.read_csv(\"../input/banfakepreprocessed/Authentic-48K.csv\")\ndf_fake = pd.read_csv(\"../input/banfakepreprocessed/Fake-1K.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:53.107011Z","iopub.execute_input":"2021-09-17T17:36:53.107540Z","iopub.status.idle":"2021-09-17T17:36:55.987183Z","shell.execute_reply.started":"2021-09-17T17:36:53.107499Z","shell.execute_reply":"2021-09-17T17:36:55.986336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = pd.concat([df_true, df_fake], axis = 0)\ndataset","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:55.988478Z","iopub.execute_input":"2021-09-17T17:36:55.988699Z","iopub.status.idle":"2021-09-17T17:36:56.003727Z","shell.execute_reply.started":"2021-09-17T17:36:55.988673Z","shell.execute_reply":"2021-09-17T17:36:56.002594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_true, count_fake = dataset[\"label\"].value_counts()\ncount_true, count_fake","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:56.004991Z","iopub.execute_input":"2021-09-17T17:36:56.005235Z","iopub.status.idle":"2021-09-17T17:36:56.012970Z","shell.execute_reply.started":"2021-09-17T17:36:56.005200Z","shell.execute_reply":"2021-09-17T17:36:56.011930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Initializing\n### 4.1. Count Vectorization","metadata":{}},{"cell_type":"code","source":"def count(data):\n    \n    df_temp = data.copy(deep = True)\n\n    count_vectorizer = CountVectorizer()\n    count_vectorizer.fit(df_temp['content'])\n\n    list_corpus = df_temp[\"content\"].tolist()\n    list_labels = df_temp[\"label\"].tolist()\n    \n    X = count_vectorizer.transform(list_corpus)\n    \n    return X, list_labels","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:56.014304Z","iopub.execute_input":"2021-09-17T17:36:56.014528Z","iopub.status.idle":"2021-09-17T17:36:56.022619Z","shell.execute_reply.started":"2021-09-17T17:36:56.014503Z","shell.execute_reply":"2021-09-17T17:36:56.021643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2. Tfidf Vectorization","metadata":{}},{"cell_type":"code","source":"def tfidf(data, ngrams = 1):\n\n    df_temp = data.copy(deep = True)\n    \n    tfidf_vectorizer = TfidfVectorizer(ngram_range = (1, ngrams))\n    tfidf_vectorizer.fit(df_temp['content'])\n\n    list_corpus = df_temp[\"content\"].tolist()\n    list_labels = df_temp[\"label\"].tolist()\n\n    X = tfidf_vectorizer.transform(list_corpus)\n    \n    return X, list_labels","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:56.024745Z","iopub.execute_input":"2021-09-17T17:36:56.025053Z","iopub.status.idle":"2021-09-17T17:36:56.038099Z","shell.execute_reply.started":"2021-09-17T17:36:56.025015Z","shell.execute_reply":"2021-09-17T17:36:56.037016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Defining Models\n### 5.1. Logistic Regression","metadata":{}},{"cell_type":"code","source":"def logistic_regression(X_train, X_test, y_train, y_test, preprocessor):\n    \n    folds = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 40)\n    \n    clf = LogisticRegressionCV(cv = folds, solver = 'saga', multi_class = 'multinomial', n_jobs = -1)\n    clf.fit(X_train, y_train)\n\n    result = pd.DataFrame(columns = ['Preprocessing', 'Model', 'Accuracy', 'F1-score-0', 'F1-score-1'])\n    \n    y_pred = clf.predict(X_test)\n    \n    accuracy = accuracy_score(y_test, y_pred)\n    precision, recall, fscore, support = score(y_test, y_pred)\n    \n    result = result.append({'Preprocessing': preprocessor, \n                            'Model': f'Logistic Regression', 'Accuracy': accuracy,\n                            'F1-score-0': fscore[0], 'F1-score-1': fscore[1]}, ignore_index = True)\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:56.041947Z","iopub.execute_input":"2021-09-17T17:36:56.042387Z","iopub.status.idle":"2021-09-17T17:36:56.050945Z","shell.execute_reply.started":"2021-09-17T17:36:56.042344Z","shell.execute_reply":"2021-09-17T17:36:56.049982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.2. Support Vector Machine","metadata":{}},{"cell_type":"code","source":"def support_vector_machine(X_train, X_test, y_train, y_test, preprocessor):\n    \n    clf = SVC(kernel = 'rbf', gamma = 1, C = 10)\n    clf.fit(X_train, y_train)\n\n    result = pd.DataFrame(columns = ['Preprocessing', 'Model', 'Accuracy', 'F1-score-0', 'F1-score-1'])\n    \n    y_pred = clf.predict(X_test)\n    \n    accuracy = accuracy_score(y_test, y_pred)\n    precision, recall, fscore, support = score(y_test, y_pred)\n    \n    result = result.append({'Preprocessing': preprocessor, \n                            'Model': f'Support Vector Machine', 'Accuracy': accuracy,\n                            'F1-score-0': fscore[0], 'F1-score-1': fscore[1]}, ignore_index = True)\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:56.052320Z","iopub.execute_input":"2021-09-17T17:36:56.052579Z","iopub.status.idle":"2021-09-17T17:36:56.062086Z","shell.execute_reply.started":"2021-09-17T17:36:56.052551Z","shell.execute_reply":"2021-09-17T17:36:56.061040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Modeling\n### 6.1. Baseline","metadata":{}},{"cell_type":"code","source":"# result_baseline = pd.DataFrame(columns = ['Preprocessing', 'Model', 'Accuracy', 'F1-score-0', 'F1-score-1'])\n\n# # Using Count\n# X, y = count(dataset)\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n# result_baseline = result_baseline.append(logistic_regression(X_train, X_test, y_train, y_test, 'Count Vectorizer'), ignore_index = True)\n# result_baseline = result_baseline.append(support_vector_machine(X_train, X_test, y_train, y_test, 'Count Vectorizer'), ignore_index = True)\n\n\n# # Using Tfidf 1-gram\n# X, y = tfidf(dataset)\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n# result_baseline = result_baseline.append(logistic_regression(X_train, X_test, y_train, y_test, 'Tfidf 1-gram'), ignore_index = True)\n# result_baseline = result_baseline.append(support_vector_machine(X_train, X_test, y_train, y_test, 'Tfidf 1-gram'), ignore_index = True)\n\n# # Using Tfidf 2-gram\n# X, y = tfidf(dataset, ngrams = 2)\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n# result_baseline = result_baseline.append(logistic_regression(X_train, X_test, y_train, y_test, 'Tfidf 2-gram'), ignore_index = True)\n# result_baseline = result_baseline.append(support_vector_machine(X_train, X_test, y_train, y_test, 'Tfidf 2-gram'), ignore_index = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:56.063349Z","iopub.execute_input":"2021-09-17T17:36:56.063727Z","iopub.status.idle":"2021-09-17T17:36:56.078016Z","shell.execute_reply.started":"2021-09-17T17:36:56.063692Z","shell.execute_reply":"2021-09-17T17:36:56.077143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.2. Model Stacking","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# result_baseline","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:56.079538Z","iopub.execute_input":"2021-09-17T17:36:56.079760Z","iopub.status.idle":"2021-09-17T17:36:56.091839Z","shell.execute_reply.started":"2021-09-17T17:36:56.079737Z","shell.execute_reply":"2021-09-17T17:36:56.091098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. Oversampling\n### 7.1. Random Over Sampling","metadata":{}},{"cell_type":"code","source":"naive_over_sample = RandomOverSampler(sampling_strategy = 'minority')\nX, y = count(dataset)\nprint(f\"Initial set observations {X.shape[0]}\")\nprint(f\"Initial set target classes {len(set(y))}\")\nX, y = naive_over_sample.fit_resample(X, y)\nprint(f\"Modified set observations {X.shape[0]}\")\nprint(f\"Modified set target classes {len(set(y))}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:56.093308Z","iopub.execute_input":"2021-09-17T17:36:56.093556Z","iopub.status.idle":"2021-09-17T17:36:56.361974Z","shell.execute_reply.started":"2021-09-17T17:36:56.093531Z","shell.execute_reply":"2021-09-17T17:36:56.360738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_over = pd.DataFrame(columns = ['Preprocessing', 'Model', 'Accuracy', 'F1-score-0', 'F1-score-1'])\n\n# Using Count\nX, y = count(dataset)\nX, y = naive_over_sample.fit_resample(X, y)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\nresult_over = result_over.append(logistic_regression(X_train, X_test, y_train, y_test, 'Count Vectorizer'), ignore_index = True)\nresult_over = result_over.append(support_vector_machine(X_train, X_test, y_train, y_test, 'Count Vectorizer'), ignore_index = True)\n\n\n# Using Tfidf 1-gram\nX, y = tfidf(dataset)\nX, y = naive_over_sample.fit_resample(X, y)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\nresult_over = result_over.append(logistic_regression(X_train, X_test, y_train, y_test, 'Tfidf 1-gram'), ignore_index = True)\nresult_over = result_over.append(support_vector_machine(X_train, X_test, y_train, y_test, 'Tfidf 1-gram'), ignore_index = True)\n\n# Using Tfidf 2-gram\nX, y = tfidf(dataset, ngrams = 2)\nX, y = naive_over_sample.fit_resample(X, y)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\nresult_over = result_over.append(logistic_regression(X_train, X_test, y_train, y_test, 'Tfidf 2-gram'), ignore_index = True)\nresult_over = result_over.append(support_vector_machine(X_train, X_test, y_train, y_test, 'Tfidf 2-gram'), ignore_index = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:56.363402Z","iopub.status.idle":"2021-09-17T17:36:56.363904Z","shell.execute_reply.started":"2021-09-17T17:36:56.363635Z","shell.execute_reply":"2021-09-17T17:36:56.363659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_over","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:56.365509Z","iopub.status.idle":"2021-09-17T17:36:56.365972Z","shell.execute_reply.started":"2021-09-17T17:36:56.365714Z","shell.execute_reply":"2021-09-17T17:36:56.365737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7.2. SMOTE","metadata":{}},{"cell_type":"code","source":"smote = SMOTE(sampling_strategy = 'minority')\nX, y = count(dataset)\nprint(f\"Initial set observations {X.shape[0]}\")\nprint(f\"Initial set target classes {len(set(y))}\")\nX, y = smote.fit_resample(X, y)\nprint(f\"Modified set observations {X.shape[0]}\")\nprint(f\"Modified set target classes {len(set(y))}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:56.367197Z","iopub.status.idle":"2021-09-17T17:36:56.367511Z","shell.execute_reply.started":"2021-09-17T17:36:56.367343Z","shell.execute_reply":"2021-09-17T17:36:56.367358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_smote = pd.DataFrame(columns = ['Preprocessing', 'Model', 'Accuracy', 'F1-score-0', 'F1-score-1'])\n\n# Using Count\nX, y = count(dataset)\nX, y = smote.fit_resample(X, y)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\nresult_smote = result_smote.append(logistic_regression(X_train, X_test, y_train, y_test, 'Count Vectorizer'), ignore_index = True)\nresult_smote = result_smote.append(support_vector_machine(X_train, X_test, y_train, y_test, 'Count Vectorizer'), ignore_index = True)\n\n\n# Using Tfidf 1-gram\nX, y = tfidf(dataset)\nX, y = smote.fit_resample(X, y)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\nresult_smote = result_smote.append(logistic_regression(X_train, X_test, y_train, y_test, 'Tfidf 1-gram'), ignore_index = True)\nresult_smote = result_smote.append(support_vector_machine(X_train, X_test, y_train, y_test, 'Tfidf 1-gram'), ignore_index = True)\n\n# Using Tfidf 2-gram\nX, y = tfidf(dataset, ngrams = 2)\nX, y = smote.fit_resample(X, y)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\nresult_smote = result_smote.append(logistic_regression(X_train, X_test, y_train, y_test, 'Tfidf 2-gram'), ignore_index = True)\nresult_smote = result_smote.append(support_vector_machine(X_train, X_test, y_train, y_test, 'Tfidf 2-gram'), ignore_index = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:56.368387Z","iopub.status.idle":"2021-09-17T17:36:56.368664Z","shell.execute_reply.started":"2021-09-17T17:36:56.368523Z","shell.execute_reply":"2021-09-17T17:36:56.368537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_smote","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:56.369817Z","iopub.status.idle":"2021-09-17T17:36:56.370141Z","shell.execute_reply.started":"2021-09-17T17:36:56.369993Z","shell.execute_reply":"2021-09-17T17:36:56.370008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7.3. ADASYN","metadata":{}},{"cell_type":"code","source":"adasyn = ADASYN(sampling_strategy = 'minority')\nX, y = count(dataset)\nprint(f\"Initial set observations {X.shape[0]}\")\nprint(f\"Initial set target classes {len(set(y))}\")\nX, y = smote.fit_resample(X, y)\nprint(f\"Modified set observations {X.shape[0]}\")\nprint(f\"Modified set target classes {len(set(y))}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:56.370955Z","iopub.status.idle":"2021-09-17T17:36:56.371227Z","shell.execute_reply.started":"2021-09-17T17:36:56.371088Z","shell.execute_reply":"2021-09-17T17:36:56.371102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_adasyn = pd.DataFrame(columns = ['Preprocessing', 'Model', 'Accuracy', 'F1-score-0', 'F1-score-1'])\n\n# Using Count\nX, y = count(dataset)\nX, y = adasyn.fit_resample(X, y)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\nresult_adasyn = result_adasyn.append(logistic_regression(X_train, X_test, y_train, y_test, 'Count Vectorizer'), ignore_index = True)\nresult_adasyn = result_adasyn.append(support_vector_machine(X_train, X_test, y_train, y_test, 'Count Vectorizer'), ignore_index = True)\n\n\n# Using Tfidf 1-gram\nX, y = tfidf(dataset)\nX, y = adasyn.fit_resample(X, y)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\nresult_adasyn = result_adasyn.append(logistic_regression(X_train, X_test, y_train, y_test, 'Tfidf 1-gram'), ignore_index = True)\nresult_adasyn = result_adasyn.append(support_vector_machine(X_train, X_test, y_train, y_test, 'Tfidf 1-gram'), ignore_index = True)\n\n# Using Tfidf 2-gram\nX, y = tfidf(dataset, ngrams = 2)\nX, y = adasyn.fit_resample(X, y)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\nresult_adasyn = result_adasyn.append(logistic_regression(X_train, X_test, y_train, y_test, 'Tfidf 2-gram'), ignore_index = True)\nresult_adasyn = result_adasyn.append(support_vector_machine(X_train, X_test, y_train, y_test, 'Tfidf 2-gram'), ignore_index = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:56.372054Z","iopub.status.idle":"2021-09-17T17:36:56.372330Z","shell.execute_reply.started":"2021-09-17T17:36:56.372191Z","shell.execute_reply":"2021-09-17T17:36:56.372205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_adasyn","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:36:56.373241Z","iopub.status.idle":"2021-09-17T17:36:56.373540Z","shell.execute_reply.started":"2021-09-17T17:36:56.373379Z","shell.execute_reply":"2021-09-17T17:36:56.373393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}