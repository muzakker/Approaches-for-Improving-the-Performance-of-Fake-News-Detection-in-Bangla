{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Imports","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# Imports\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#import tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom imblearn.under_sampling import NearMiss, RandomUnderSampler\nfrom imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n\nfrom mlxtend.classifier import StackingCVClassifier\n\nfrom joblib import dump, load","metadata":{"execution":{"iopub.status.busy":"2021-09-27T04:03:52.316018Z","iopub.execute_input":"2021-09-27T04:03:52.317128Z","iopub.status.idle":"2021-09-27T04:03:53.789199Z","shell.execute_reply.started":"2021-09-27T04:03:52.316998Z","shell.execute_reply":"2021-09-27T04:03:53.788078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from warnings import simplefilter\nfrom sklearn.exceptions import ConvergenceWarning\nsimplefilter(\"ignore\", category=ConvergenceWarning)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T04:03:53.791131Z","iopub.execute_input":"2021-09-27T04:03:53.79144Z","iopub.status.idle":"2021-09-27T04:03:53.799514Z","shell.execute_reply.started":"2021-09-27T04:03:53.791404Z","shell.execute_reply":"2021-09-27T04:03:53.798067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to evaluate: accuracy, precision, recall, f1-score\n\ndef calculate_results(y_true, y_pred):\n  \"\"\"\n  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n\n  Args:\n  -----\n  y_true = true labels in the form of a 1D array\n  y_pred = predicted labels in the form of a 1D array\n\n  Returns a dictionary of accuracy, precision, recall, f1-score.\n  \"\"\"\n  # Calculate model accuracy\n  model_accuracy = accuracy_score(y_true, y_pred) * 100\n  # Calculate model precision, recall and f1 score using \"weighted\" average\n  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n  model_results = {\"accuracy\": model_accuracy,\n                  \"precision\": model_precision,\n                  \"recall\": model_recall,\n                  \"f1\": model_f1}\n  return model_results\n\n\n# Create a helper function to compare our baseline results to new model results\ndef compare_baseline_to_new_results(baseline_results, new_model_results):\n  for key, value in baseline_results.items():\n    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-27T04:03:53.801125Z","iopub.execute_input":"2021-09-27T04:03:53.802194Z","iopub.status.idle":"2021-09-27T04:03:53.812619Z","shell.execute_reply.started":"2021-09-27T04:03:53.802147Z","shell.execute_reply":"2021-09-27T04:03:53.811509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the font scale\nsns.set(font_scale = 1.5)\n\ndef plot_conf_mat(conf_mat):\n    \"\"\"\n    Plots a confusion matrix using Seaborn's heatmap().\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(4, 4))\n    ax = sns.heatmap(conf_mat,\n                     fmt=\"d\",\n                     annot=True, # Annotate the boxes \n                     cbar=False)\n    plt.xlabel('Predicted label')\n    plt.ylabel('True label');","metadata":{"execution":{"iopub.status.busy":"2021-09-27T04:03:53.814831Z","iopub.execute_input":"2021-09-27T04:03:53.815733Z","iopub.status.idle":"2021-09-27T04:03:53.832656Z","shell.execute_reply.started":"2021-09-27T04:03:53.815688Z","shell.execute_reply":"2021-09-27T04:03:53.83169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Data","metadata":{}},{"cell_type":"code","source":"df_true = pd.read_csv(\"Authentic-48K.csv\")\ndf_fake = pd.read_csv(\"Fake-1K.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-27T04:03:53.834241Z","iopub.execute_input":"2021-09-27T04:03:53.835067Z","iopub.status.idle":"2021-09-27T04:03:57.346975Z","shell.execute_reply.started":"2021-09-27T04:03:53.835021Z","shell.execute_reply":"2021-09-27T04:03:57.346073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = pd.concat([df_true, df_fake], axis = 0)\ndataset","metadata":{"execution":{"iopub.status.busy":"2021-09-27T04:03:57.34835Z","iopub.execute_input":"2021-09-27T04:03:57.348676Z","iopub.status.idle":"2021-09-27T04:03:57.376868Z","shell.execute_reply.started":"2021-09-27T04:03:57.348635Z","shell.execute_reply":"2021-09-27T04:03:57.375858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_true, count_fake = dataset[\"label\"].value_counts()\ncount_true, count_fake","metadata":{"execution":{"iopub.status.busy":"2021-09-27T04:03:57.378417Z","iopub.execute_input":"2021-09-27T04:03:57.379093Z","iopub.status.idle":"2021-09-27T04:03:57.388136Z","shell.execute_reply.started":"2021-09-27T04:03:57.379048Z","shell.execute_reply":"2021-09-27T04:03:57.38713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Numerical Representations\n### 3.1. Count Vectorizer","metadata":{}},{"cell_type":"code","source":"def count(data):\n    \n    df_temp = data.copy(deep = True)\n    df = dataset.copy(deep = True)\n    df_temp[\"content\"] = df_temp[\"content\"].fillna(' ')\n    df[\"content\"] = df[\"content\"].fillna(' ')\n\n    count_vectorizer = CountVectorizer()\n    count_vectorizer.fit(df[\"content\"])\n\n    list_corpus = df_temp[\"content\"].tolist()\n    list_labels = df_temp[\"label\"].tolist()\n    \n    X = count_vectorizer.transform(list_corpus)\n    \n    return X, list_labels","metadata":{"execution":{"iopub.status.busy":"2021-09-27T04:03:57.389826Z","iopub.execute_input":"2021-09-27T04:03:57.390783Z","iopub.status.idle":"2021-09-27T04:03:57.399957Z","shell.execute_reply.started":"2021-09-27T04:03:57.39074Z","shell.execute_reply":"2021-09-27T04:03:57.399313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2. Tfidf Vectorizer","metadata":{}},{"cell_type":"code","source":"def tfidf(data, ngrams = 1):\n\n    df_temp = data.copy(deep = True)\n    df = dataset.copy(deep = True)\n    df_temp[\"content\"] = df_temp[\"content\"].fillna(' ')\n    df[\"content\"] = df[\"content\"].fillna(' ')\n    \n    tfidf_vectorizer = TfidfVectorizer(ngram_range = (1, ngrams))\n    tfidf_vectorizer.fit(df['content'])\n\n    list_corpus = df_temp[\"content\"].tolist()\n    list_labels = df_temp[\"label\"].tolist()\n\n    X = tfidf_vectorizer.transform(list_corpus)\n    \n    return X, list_labels","metadata":{"execution":{"iopub.status.busy":"2021-09-27T04:03:57.401386Z","iopub.execute_input":"2021-09-27T04:03:57.402172Z","iopub.status.idle":"2021-09-27T04:03:57.415575Z","shell.execute_reply.started":"2021-09-27T04:03:57.402126Z","shell.execute_reply":"2021-09-27T04:03:57.414525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Modeling\n### 5.1. Baseline\n#### 5.1.1. Count","metadata":{}},{"cell_type":"code","source":"# Using Count\nX, y = count(dataset)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T04:04:00.773751Z","iopub.execute_input":"2021-09-27T04:04:00.774087Z","iopub.status.idle":"2021-09-27T04:04:27.059767Z","shell.execute_reply.started":"2021-09-27T04:04:00.774053Z","shell.execute_reply":"2021-09-27T04:04:27.058795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = SVC(kernel = 'rbf', gamma = 1, C = 10, probability = True)\nclf.fit(X_train, y_train)\ndump(clf, filename = \"baseline-count-SVM-proba.joblib\")","metadata":{"execution":{"iopub.status.busy":"2021-09-27T04:04:27.061587Z","iopub.execute_input":"2021-09-27T04:04:27.0619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.1.2. TFIDF-1","metadata":{}},{"cell_type":"code","source":"# result_baseline_tfidf1 = pd.DataFrame(columns = ['Preprocessing', 'Model', 'Accuracy', 'F1-score', 'F1-score-0', 'F1-score-1'])\n\n# # Using Tfidf 1-gram\n# X, y = tfidf(dataset)\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n# result_baseline_tfidf1 = result_baseline_tfidf1.append(logistic_regression(X_train, X_test, y_train, y_test, 'Tfidf 1-gram'), ignore_index = True)\n# result_baseline_tfidf1 = result_baseline_tfidf1.append(support_vector_machine(X_train, X_test, y_train, y_test, 'Tfidf 1-gram'), ignore_index = True)\n# result_baseline_tfidf1 = result_baseline_tfidf1.append(multinomial_nb(X_train, X_test, y_train, y_test, 'Tfidf 1-gram'), ignore_index = True)\n# result_baseline_tfidf1 = result_baseline_tfidf1.append(bernoulli_nb(X_train, X_test, y_train, y_test, 'Tfidf 1-gram'), ignore_index = True)\n\n# result_baseline_tfidf1","metadata":{"execution":{"iopub.status.busy":"2021-09-17T17:35:33.667293Z","iopub.execute_input":"2021-09-17T17:35:33.667616Z","iopub.status.idle":"2021-09-17T17:36:08.698117Z","shell.execute_reply.started":"2021-09-17T17:35:33.667578Z","shell.execute_reply":"2021-09-17T17:36:08.697216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.1.3. TFIDF-2","metadata":{}},{"cell_type":"code","source":"# Using Tfidf 2-gram\nX, y = tfidf(dataset, ngrams = 2)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T05:27:31.906997Z","iopub.execute_input":"2021-09-21T05:27:31.907301Z","iopub.status.idle":"2021-09-21T05:28:25.145764Z","shell.execute_reply.started":"2021-09-21T05:27:31.907273Z","shell.execute_reply":"2021-09-21T05:28:25.144876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = SVC(kernel = 'rbf', gamma = 1, C = 10, probability = True)\nclf.fit(X_train, y_train)\ndump(clf, filename = \"baseline-tfidf2-SVM-proba.joblib\")","metadata":{},"execution_count":null,"outputs":[]}]}